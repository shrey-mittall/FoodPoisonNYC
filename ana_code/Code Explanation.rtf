{\rtf1\ansi\ansicpg1252\cocoartf2708
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;}
{\colortbl;\red255\green255\blue255;}
{\*\expandedcolortbl;;}
\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx720\tx1440\tx2160\tx2880\tx3600\tx4320\tx5040\tx5760\tx6480\tx7200\tx7920\tx8640\pardirnatural\partightenfactor0

\f0\fs24 \cf0 The MapReduce screenshots are the first part of the project, and they involve taking the data from the CURL  and NYC open data, and ingesting it as a CSV. Then the Map Reduce does some cleaning, like taking out the data that does not have all the parameters that we need and is not usable. It also counts the number of records before and after. After this, the csv that comes out of Map Reduce is taken in by the Scala program and is further modified into a dataframe, which is manipulated and used to derive conclusions on correlation and to create a multinomial linear regression model for the data. }